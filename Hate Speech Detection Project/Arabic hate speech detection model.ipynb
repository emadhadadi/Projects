{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4278143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emhad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('arabic')\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pyarabic.araby import strip_tashkeel \n",
    "from pyarabic.araby import strip_tatweel \n",
    "from pyarabic.araby import normalize_hamza\n",
    "import numpy as np\n",
    "import imblearn\n",
    "print(imblearn.__version__)\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix,plot_confusion_matrix\n",
    "import matplotlib as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716b62c",
   "metadata": {},
   "source": [
    "Arabic Hate speech Lixcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b362730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The Arabic Hate speech Lixcon\n",
    "#___________________________________\n",
    "Lixcon = pd.read_excel('Lixcon.xlsx' ) #|\n",
    "Lixcon = Lixcon.squeeze()                  #|\n",
    "Lixcon = list(Lixcon)                      #|\n",
    "#__________________________________#|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655e2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                  __________________________________________\n",
    "#                 | Reading The Train Dataset      |\n",
    "#___________________________________________________________________________________\n",
    "train = pd.read_excel('Hate speech 20 nov.xlsx' , sheet_name =\"new_Training_data\") #|\n",
    "combi = train.copy()                                                               #|\n",
    "#__________________________________________________________________________________#|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98cced",
   "metadata": {},
   "source": [
    "<b>preprocessing <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20787e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#        _____________________________________________________________\n",
    "#       | This function performs the entire preprocessing of the data\n",
    "\n",
    "\n",
    "def pre_processing(combi):\n",
    "    combi[\"Lixcon\"] = combi['text'].apply(lambda x: len([x for x in x.split() if x in Lixcon]))\n",
    "    combi['word_count']= combi['text'].apply(lambda x : len(str(x).split(' ')))\n",
    "    combi['stopwords_count'] = combi['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "    combi['text'] = combi['text'].apply(lambda x: str(strip_tashkeel(x)))\n",
    "    combi['text'] = combi['text'].apply(lambda x: str(strip_tatweel(x)))\n",
    "    combi['text'] = combi['text'].str.replace(\"[إأٱآا]\", \"ا\")\n",
    "    combi['text'] = combi['text'].str.replace(\"[ؤ]\", \"و\")\n",
    "    combi['text'] = combi['text'].str.replace('[\\d]',' ')\n",
    "    combi['text'] = combi['text'].str.replace('[^\\w\\s]',' ')\n",
    "    combi['text'] = combi['text'].str.replace('[a-zA-Z]',' ') \n",
    "    combi['text'] = combi['text'].str.replace('[_]',' ')\n",
    "    combi['text'] = combi['text'].apply(lambda x: \" \".join(x.split()))\n",
    "    combi['text'] = combi['text'].str.strip()\n",
    "    combi['text'].replace([\" \",\"\"] , np.nan, inplace=True)\n",
    "    combi.dropna(subset=['text'], inplace=True)\n",
    "    combi['text'] = combi['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    st = ISRIStemmer()\n",
    "    combi['text'] = combi['text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()])) \n",
    "    return combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22cd7934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\2569263154.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi['text'] = combi['text'].str.replace(\"[إأٱآا]\", \"ا\")\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\2569263154.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi['text'] = combi['text'].str.replace(\"[ؤ]\", \"و\")\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\2569263154.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi['text'] = combi['text'].str.replace('[\\d]',' ')\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\2569263154.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi['text'] = combi['text'].str.replace('[^\\w\\s]',' ')\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\2569263154.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi['text'] = combi['text'].str.replace('[a-zA-Z]',' ')\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\2569263154.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi['text'] = combi['text'].str.replace('[_]',' ')\n"
     ]
    }
   ],
   "source": [
    "combi = pre_processing(combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca8d84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#           ______________________________________________\n",
    "#          | Term Frequency–Inverse Document Frequency  (TF-IDF)  |\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8,min_df=5 )\n",
    "tfidf = tfidf_vectorizer.fit_transform(combi['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16b9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                  _________________________________________\n",
    "#                 |      This code adds basic features to TF-IDF matrix      |\n",
    "\n",
    "Basic_Featue_Extraction = combi[[ 'Lixcon' , 'word_count', 'stopwords_count']].to_numpy()\n",
    "Basic_Featue_Extraction = Basic_Featue_Extraction.astype(float)\n",
    "\n",
    "All_Features = np.concatenate((tfidf.toarray(), Basic_Featue_Extraction), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9855ab7",
   "metadata": {},
   "source": [
    "<b> Model Building <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b00522",
   "metadata": {},
   "source": [
    "Random Forest <b>(best results) <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2629bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of Random forest is --> 0.9185558354324097\n",
      "0.9148375768217735\n",
      "0.9270462633451957\n",
      "0.902946273830156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       614\n",
      "           1       0.93      0.90      0.91       577\n",
      "\n",
      "    accuracy                           0.92      1191\n",
      "   macro avg       0.92      0.92      0.92      1191\n",
      "weighted avg       0.92      0.92      0.92      1191\n",
      "\n",
      "[[573  41]\n",
      " [ 56 521]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\emhad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x154045fceb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#                  ______________________________________________\n",
    "#                 |                 Model Building               |\n",
    "\n",
    "\n",
    "\n",
    "#   Building the model using Random Forest algorithm\n",
    "\n",
    "\n",
    "train_tf = All_Features[0:]\n",
    "\n",
    "# splitting data into training and test set using train_test_split function\n",
    "Tr_D_bow, Te_D_bow, Tr_L_bow , Te_L_bow = train_test_split(train_tf, combi['class'], random_state=45, test_size=0.2)\n",
    "# Create Random Forest classifer object\n",
    "RF = RandomForestClassifier()\n",
    "# Train Random Forest  Classifer\n",
    "RF = RF.fit(Tr_D_bow,Tr_L_bow)\n",
    "#Predict the response for test dataset\n",
    "RF_prediction = RF.predict(Te_D_bow)\n",
    "\n",
    "\n",
    "#These codes print the results of the model\n",
    "print('The Accuracy of Random forest is -->',metrics.accuracy_score(Te_L_bow, RF_prediction))\n",
    "print(metrics.f1_score(Te_L_bow, RF_prediction))\n",
    "print(metrics.precision_score(Te_L_bow, RF_prediction))\n",
    "print(metrics.recall_score(Te_L_bow, RF_prediction))\n",
    "print(classification_report(Te_L_bow,RF_prediction))\n",
    "\n",
    "\n",
    "#This code visualize the results as a matrix\n",
    "print(confusion_matrix(Te_L_bow,RF_prediction))\n",
    "plot_confusion_matrix(RF,Te_D_bow,Te_L_bow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c294c",
   "metadata": {},
   "source": [
    "SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65a65f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of SVMC is --> 0.8597816960537363\n",
      "0.8496849684968497\n",
      "0.8838951310861424\n",
      "0.8180242634315424\n"
     ]
    }
   ],
   "source": [
    "# Building the model Using SVM algorithm\n",
    "\n",
    "\n",
    "train_tf = All_Features[0:]\n",
    "\n",
    "\n",
    "# splitting data into training and test set using train_test_split function\n",
    "Tr_D_bow, Te_D_bow, Tr_L_bow , Te_L_bow = train_test_split(train_tf, combi['class'], random_state=45, test_size=0.2)\n",
    "# Create SVM classifer object\n",
    "SVM = svm.SVC()\n",
    "# Train SVM Classifer\n",
    "SVM = SVM.fit(Tr_D_bow,Tr_L_bow)\n",
    "#Predict the response for test dataset\n",
    "SVM_prediction = SVM.predict(Te_D_bow)\n",
    "\n",
    "\n",
    "#These codes print the results of the model\n",
    "print('The Accuracy of SVMC is -->',metrics.accuracy_score(Te_L_bow, SVM_prediction))\n",
    "print(metrics.f1_score(Te_L_bow, SVM_prediction))\n",
    "print(metrics.precision_score(Te_L_bow, SVM_prediction))\n",
    "print(metrics.recall_score(Te_L_bow, SVM_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43243712",
   "metadata": {},
   "source": [
    "Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e91256a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of naive bayes is --> 0.799328295549958\n",
      "0.8016597510373443\n",
      "0.7691082802547771\n",
      "0.8370883882149047\n"
     ]
    }
   ],
   "source": [
    "# Building the model Naïve Bayes algorithm\n",
    "\n",
    "\n",
    "train_tf = All_Features[0:]\n",
    "\n",
    "# splitting data into training and test set using train_test_split function\n",
    "Tr_D_bow, Te_D_bow, Tr_L_bow , Te_L_bow = train_test_split(train_tf, combi['class'], random_state=45, test_size=0.2)\n",
    "#Create Naïve Bayes Gaussian Classifier object\n",
    "Nbayes = GaussianNB()\n",
    "# Train Naïve Bayes Classifer\n",
    "Nbayes.fit(Tr_D_bow,Tr_L_bow)\n",
    "#Predict the response for test dataset\n",
    "Nbayes_prediction= Nbayes.predict(Te_D_bow)\n",
    "\n",
    "#These codes print the results of the model\n",
    "print('The Accuracy of naive bayes is -->',metrics.accuracy_score(Te_L_bow, Nbayes_prediction))\n",
    "print(metrics.f1_score(Te_L_bow, Nbayes_prediction))\n",
    "print(metrics.precision_score(Te_L_bow, Nbayes_prediction))\n",
    "print(metrics.recall_score(Te_L_bow, Nbayes_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362aaa3",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80773417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of Decision Tree is --> 0.8648194794290512\n",
      "0.8613264427217917\n",
      "0.8561643835616438\n",
      "0.8665511265164645\n"
     ]
    }
   ],
   "source": [
    "# Building the model Decision Tree algorithm\n",
    "\n",
    "\n",
    "train_tf = All_Features[0:]\n",
    "\n",
    "# splitting data into training and test set using train_test_split function\n",
    "Tr_D_bow, Te_D_bow, Tr_L_bow , Te_L_bow = train_test_split(train_tf, combi['class'], random_state=45, test_size=0.2)\n",
    "# Create Decision Tree classifer object\n",
    "Decision_tree = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "Decision_tree = Decision_tree.fit(Tr_D_bow,Tr_L_bow)\n",
    "#Predict the response for test dataset\n",
    "Decision_tree_prediction = Decision_tree.predict(Te_D_bow)\n",
    "\n",
    "\n",
    "#These codes print the results of the model\n",
    "print('The Accuracy of Decision Tree is -->',metrics.accuracy_score(Te_L_bow, Decision_tree_prediction))\n",
    "print(metrics.f1_score(Te_L_bow, Decision_tree_prediction))\n",
    "print(metrics.precision_score(Te_L_bow, Decision_tree_prediction))\n",
    "print(metrics.recall_score(Te_L_bow, Decision_tree_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0137e",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a930d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of Logistic Regression is --> 0.9126784214945424\n",
      "0.9071428571428573\n",
      "0.9355432780847146\n",
      "0.8804159445407279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\emhad\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Building the model Logistic Regression algorithm\n",
    "\n",
    "\n",
    "\n",
    "train_tf = All_Features[0:]\n",
    "\n",
    "\n",
    "# splitting data into training and test set using train_test_split function\n",
    "Tr_D_bow, Te_D_bow, Tr_L_bow , Te_L_bow = train_test_split(train_tf, combi['class'], random_state=45, test_size=0.2)\n",
    "#Create Logistic Regression Classifier object\n",
    "Logregression = LogisticRegression()\n",
    "# Train Logistic Regression Classifer\n",
    "Logregression.fit(Tr_D_bow,Tr_L_bow)\n",
    "#Predict the response for test dataset\n",
    "Logregression_prediction=Logregression.predict(Te_D_bow)\n",
    "\n",
    "#These codes print the results of the model\n",
    "print('The Accuracy of Logistic Regression is -->',metrics.accuracy_score(Te_L_bow, Logregression_prediction))\n",
    "print(metrics.f1_score(Te_L_bow, Logregression_prediction))\n",
    "print(metrics.precision_score(Te_L_bow, Logregression_prediction))\n",
    "print(metrics.recall_score(Te_L_bow, Logregression_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd28aca",
   "metadata": {},
   "source": [
    "k-nearest neighbors(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2d6c33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of KNN is --> 0.8505457598656591\n",
      "0.8438596491228071\n",
      "0.8543516873889876\n",
      "0.8336221837088388\n"
     ]
    }
   ],
   "source": [
    "# Building the model k-nearest neighbors(KNN)\n",
    "\n",
    "train_tf = All_Features[0:]\n",
    "\n",
    "# splitting data into training and test set using train_test_split function\n",
    "Tr_D_bow, Te_D_bow, Tr_L_bow , Te_L_bow = train_test_split(train_tf, combi['class'], random_state=45, test_size=0.2)\n",
    "#Create KNN Classifier object\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Train Knn Classifer\n",
    "knn.fit(Tr_D_bow, Tr_L_bow)\n",
    "#Predict the response for test dataset\n",
    "knn_prediction = knn.predict(Te_D_bow)\n",
    "\n",
    "\n",
    "#These codes print the results of the model\n",
    "print('The Accuracy of KNN is -->',metrics.accuracy_score(Te_L_bow, knn_prediction))\n",
    "print(metrics.f1_score(Te_L_bow, knn_prediction))\n",
    "print(metrics.precision_score(Te_L_bow, knn_prediction))\n",
    "print(metrics.recall_score(Te_L_bow, knn_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a119a0f3",
   "metadata": {},
   "source": [
    " k-means cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89627a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of KNN is --> 0.4431570109151973\n",
      "0.26441881100266196\n",
      "0.3791348600508906\n",
      "0.20299727520435967\n"
     ]
    }
   ],
   "source": [
    "# Building the model using k-means cluster\n",
    "\n",
    "\n",
    "train_tf = All_Features[0:]\n",
    "\n",
    "#Create k-means Classifier object\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "# Train k-eans Classifer\n",
    "kmeans.fit(All_Features)\n",
    "#Predict the response for test dataset\n",
    "kmeans_pre = kmeans.predict(All_Features)\n",
    "\n",
    "#These codes print the results of the model\n",
    "print('The Accuracy of KNN is -->',metrics.accuracy_score(combi['class'], kmeans.labels_))\n",
    "print(metrics.f1_score(combi['class'], kmeans.labels_))\n",
    "print(metrics.precision_score(combi['class'], kmeans.labels_))\n",
    "print(metrics.recall_score(combi['class'], kmeans.labels_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69806d0f",
   "metadata": {},
   "source": [
    " Model Evaluation & Testing  using out of sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28e5e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____________________ Model Evaluation & Testing  using out of sample Data ____________\n",
    "\n",
    "# read the Data\n",
    "train1 = pd.read_excel('Testing.xlsx', sheet_name=\"testing 2\")\n",
    "\n",
    "combi1 = train1.copy()\n",
    "\n",
    "combi1['Tweet'] = combi1['Tweet'].astype(str)\n",
    "\n",
    "\n",
    "#        _____________________________________________________________\n",
    "#       | This function performs the entire preprocessing of the data\n",
    "\n",
    "def pre_processing1(combi1):\n",
    "    combi1['Tweet'] = combi1['Tweet'].apply(lambda x: str(strip_tashkeel(x)))\n",
    "    combi1['Tweet'] = combi1['Tweet'].apply(lambda x: str(strip_tatweel(x)))\n",
    "    combi1['Tweet'] = combi1['Tweet'].str.replace(\"[إأٱآا]\", \"ا\")\n",
    "    combi1['Tweet'] = combi1['Tweet'].str.replace(\"[ؤ]\", \"و\")\n",
    "    combi1['Tweet'] = combi1['Tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    combi1['Tweet'] = combi1['Tweet'].str.replace('[\\d]',' ')\n",
    "    combi1['Tweet'] = combi1['Tweet'].str.replace('[^\\w\\s]',' ')\n",
    "    combi1['Tweet'] = combi1['Tweet'].str.replace('[a-zA-Z]',' ') \n",
    "    combi1['Tweet'] = combi1['Tweet'].str.replace('[_]',' ')  \n",
    "    combi1['Tweet'] = combi1['Tweet'].apply(lambda x: \" \".join(x.split()))\n",
    "    combi1['Tweet'] = combi1['Tweet'].str.strip()\n",
    "    combi1['Tweet'].replace([\" \",\"\"] , np.nan, inplace=True)\n",
    "    combi1.dropna(subset=['Tweet'], inplace=True)\n",
    "    combi1[\"Lixcon\"] = combi1['Tweet'].apply(lambda x: len([x for x in x.split() if x in Lixcon]))\n",
    "    combi1['word_count']= combi1['Tweet'].apply(lambda x : len(str(x).split(' ')))\n",
    "    combi1['stopwords_count'] = combi1['Tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "    combi1['Tweet'] = combi1['Tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    st = ISRIStemmer()\n",
    "    combi1['Tweet'] = combi1['Tweet'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()])) \n",
    "    return combi1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f6283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\1568609786.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi1['Tweet'] = combi1['Tweet'].str.replace(\"[إأٱآا]\", \"ا\")\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\1568609786.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi1['Tweet'] = combi1['Tweet'].str.replace(\"[ؤ]\", \"و\")\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\1568609786.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi1['Tweet'] = combi1['Tweet'].str.replace('[\\d]',' ')\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\1568609786.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi1['Tweet'] = combi1['Tweet'].str.replace('[^\\w\\s]',' ')\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\1568609786.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi1['Tweet'] = combi1['Tweet'].str.replace('[a-zA-Z]',' ')\n",
      "C:\\Users\\emhad\\AppData\\Local\\Temp\\ipykernel_2680\\1568609786.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  combi1['Tweet'] = combi1['Tweet'].str.replace('[_]',' ')\n"
     ]
    }
   ],
   "source": [
    "combi1 = pre_processing1(combi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39dc419f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of RF is --> 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf1 = tfidf_vectorizer.transform(combi1['Tweet'])\n",
    "\n",
    "\n",
    "#                  _________________________________________\n",
    "#                 |      This code adds basic features to TF-IDF matrix      |\n",
    "\n",
    "Basic_Featue_Extraction1 = combi1[[ 'Lixcon' , 'word_count', 'stopwords_count']].to_numpy()\n",
    "Basic_Featue_Extraction1 = Basic_Featue_Extraction1.astype(float)\n",
    "All_Features_2 = np.concatenate((tfidf1.toarray(), Basic_Featue_Extraction1), axis=1)\n",
    "\n",
    "\n",
    "#  using Random Forest algorithm\n",
    "predict = RF.predict( All_Features_2[0:])\n",
    "predict = pd.DataFrame(predict)\n",
    "combi1['Class'] = predict\n",
    "# To reveiw results in variable explorer in pre-cleaning part tweet with predicted column\n",
    "train1['Class'] = predict\n",
    "\n",
    "print('The Accuracy of RF is -->',metrics.accuracy_score(train1['actual'], train1['Class']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79050984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
